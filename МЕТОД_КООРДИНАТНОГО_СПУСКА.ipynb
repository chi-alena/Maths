{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBo3xGty0P0O"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMNFu0BH0ild"
      },
      "source": [
        "# **Стохастический градиентный и координатный спуски**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1EQil2H0oBG"
      },
      "source": [
        "Для каждого задания указано количество баллов (если они оцениваются отдельно) + 1 балл за аккуратное и полное выполнение всего задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haFkQJ310qjC"
      },
      "source": [
        "# **Загрузка и подготовка данных**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PotmF_EZ019N"
      },
      "source": [
        "✔Загрузите уже знакомый вам файл Advertising.csv как объект DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdCXCfp50vBx"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/Advertising.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LMb1pCR09c-"
      },
      "source": [
        "✔Проверьте, есть ли в данных пропуски и, если они есть - удалите их"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNs1asgH0-Qr",
        "outputId": "257c5bbe-5a76-46e4-f982-02dd83010742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0    0\n",
            "TV            0\n",
            "radio         0\n",
            "newspaper     0\n",
            "sales         0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(data.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm-cSrXX1t1i"
      },
      "source": [
        "Вывод по разделу:\n",
        "Пропуски не обнаружены"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRATqXy012Di"
      },
      "source": [
        "✔Преобразуйте ваши признаки в массивы NumPy и разделите их на переменные X (предикторы) и y(целевая переменная)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsNk3HGu1uut",
        "outputId": "e0ccf25c-36fe-4ce8-f2af-dbe138b4fd0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[230.1,  37.8,  69.2],\n",
              "        [ 44.5,  39.3,  45.1],\n",
              "        [ 17.2,  45.9,  69.3]]),\n",
              " array([22.1, 10.4,  9.3]))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Создание матрицы наблюдений X\n",
        "X = data.drop(['sales', 'Unnamed: 0'], axis=1).values\n",
        "\n",
        "# Вектор правильных ответов —  y\n",
        "y = data['sales'].values\n",
        "\n",
        "# check\n",
        "X[:3], y[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6x4Hyhr1-N6"
      },
      "source": [
        "# **Координатный спуск (3 балла)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me594H022A8o"
      },
      "source": [
        "✔Добавим единичный столбец для того, чтобы у нас был свободный коэффициент в уравнении регрессии:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2YX6DsC2Dq-",
        "outputId": "2dd89716-ee25-43ee-cc5e-2bf063dc3566"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  1. , 230.1,  37.8,  69.2],\n",
              "       [  1. ,  44.5,  39.3,  45.1],\n",
              "       [  1. ,  17.2,  45.9,  69.3]])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import numpy as np\n",
        "X = np.hstack([np.ones(X.shape[0]).reshape(-1, 1), X])\n",
        "\n",
        "# check\n",
        "X[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7PsxJof2Gia"
      },
      "source": [
        "✔Нормализуем данные: обычно это необходимо для корректной работы алгоритма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARn7Knms2Ite",
        "outputId": "19df6203-cf4e-4bbe-9f6a-7a39b387a1f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.07071068, 0.09561706, 0.09692057, 0.13052034],\n",
              "       [0.07071068, 0.01849178, 0.10076663, 0.08506456],\n",
              "       [0.07071068, 0.00714739, 0.11768927, 0.13070895]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = X / np.sqrt(np.sum(np.square(X), axis=0))\n",
        "\n",
        "# check\n",
        "X[:3]\n",
        "# Normalization is done by dividing each element in a column\n",
        "# by the square root of the sum of squares of all elements in that column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZYCmmAp2Lrk"
      },
      "source": [
        "✔Реализуйте алгоритм координатного спуска: (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZuojqsd2RDj"
      },
      "source": [
        "✔Вам необходимо реализовать координатный спуск, и вывести веса в модели линейной регрессии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYRdzEKv2QZ5",
        "outputId": "d5ae5a79-7210-476d-9ad9-82f0d4ea27f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 41.56217205]\n",
            " [110.13144155]\n",
            " [ 73.52860638]\n",
            " [ -0.55006384]]\n"
          ]
        }
      ],
      "source": [
        "y = y.reshape(-1, 1)\n",
        "\n",
        "num_iters = 1000\n",
        "# извлекаем размеры матрицы X\n",
        "m, n = X.shape\n",
        "w = np.zeros((n,1))  # Нулевой вектор весов\n",
        "r = y - X.dot(w)          # Инициализация остатков\n",
        "\n",
        "# Координатный спуск\n",
        "for iteration in range(num_iters):\n",
        "    for j in range(n):\n",
        "        # Вычисляем прогноз без k-ого фактора\n",
        "        h = (X[:,0:j] @ w[0:j]) + (X[:,j+1:] @ w[j+1:])\n",
        "        # Обновляем остатки, удаляя вклад текущего веса w_j\n",
        "        r = y - h\n",
        "        # Обновляем новое значение k-ого коэффициента\n",
        "        w[j] = (X[:,j].T @ (y - h))\n",
        "        # Вычисляем функцию потерь\n",
        "        cost = (sum((X @ w) - y) ** 2)/(len(y))\n",
        "\n",
        "# Выводим вектор весов\n",
        "print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fxvP0H02l51"
      },
      "source": [
        "✔Сравните результаты с реализацией линейной регрессии из библиотеки sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yq7dUxh2ejz",
        "outputId": "24b67dfa-1435-4b69-fa97-79fc8521d328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 41.56217205 110.13144155  73.52860638  -0.55006384]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression(fit_intercept=False)\n",
        "model.fit(X, y)\n",
        "\n",
        "print(model.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFup8GqI2rnK",
        "outputId": "5bada8ca-1d6d-42c1-b236-615412758666"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "230.5421897033357"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Евклидово расстояние между векторами предсказаний координатным спуском и линейной регрессией sklearn\n",
        "np.linalg.norm(w - model.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnVm8TsN2vG2"
      },
      "source": [
        "Если вы все сделали верно, они должны практически совпасть!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsiCrFoC2vxj"
      },
      "source": [
        "# **Стохастический градиентный спуск (6 баллов)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY0SuyDd21k6"
      },
      "source": [
        "\n",
        "✔Отмасштабируйте столбцы исходной матрицы X (которую мы не нормализовали еще!). Для того, чтобы это сделать, надо вычесть из каждого значения среднее и разделить на стандартное отклонение (0.5 баллов)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcMLABit259E",
        "outputId": "2373a887-1a3d-40c2-c961-e072ecf6977d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Среднее масштабированного массива: 0\n",
            "Стандартные отклонения масштабированного массива: 1\n"
          ]
        }
      ],
      "source": [
        "# Вернём изначальную (ненормализованную матрицу)\n",
        "X = np.array(data[['TV','radio','newspaper']])\n",
        "y = np.array(data['sales'])\n",
        "\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "print('Среднее масштабированного массива: %.0f'%(abs(X.mean())))\n",
        "print('Стандартные отклонения масштабированного массива: %.0f'%(X.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FeIEDYF3AMi"
      },
      "source": [
        "✔Добавим единичный столбец"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST5785K63BAn"
      },
      "outputs": [],
      "source": [
        "X = np.hstack([np.ones(X.shape[0]).reshape(-1, 1), X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfcoG6lN3DIk"
      },
      "source": [
        "✔Создайте функцию mse_error для вычисления среднеквадратичной ошибки, принимающую два аргумента: реальные значения и предсказывающие, и возвращающую значение mse (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnZ8T_wn3HBu"
      },
      "outputs": [],
      "source": [
        "def mse_error(y, y_pred):\n",
        "    \"\"\"Функция вычисления среднеквадратичной ошибки\n",
        "\n",
        "    Args:\n",
        "        y (float): реальное значение\n",
        "        y_pred (float): предсказанное значение\n",
        "    Returns:\n",
        "        result (float): значение MSE\n",
        "    \"\"\"\n",
        "    mse = ((y - y_pred) ** 2).mean()\n",
        "    return mse # Вычисляем среднее значение реальных продаж\n",
        "\n",
        "\n",
        "mean_sales = np.mean(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL8nH7Xw3M_u"
      },
      "source": [
        "✔Сделайте наивный прогноз: предскажите продажи средним значением. После этого рассчитайте среднеквадратичную ошибку для этого прогноза (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJIfdmZ-3Npa",
        "outputId": "b65c9767-02c5-4e6f-c4f7-6aa36f8b8acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наивный прогноз (среднее значение продаж): 14.0225\n",
            "Среднеквадратичная ошибка (MSE) для наивного прогноза: 27.085743750000002\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.full_like(y, mean_sales)\n",
        "# посчитаем MSE\n",
        "mse = mse_error(y, y_pred)\n",
        "\n",
        "print(\"Наивный прогноз (среднее значение продаж):\", y_pred[0])\n",
        "print(\"Среднеквадратичная ошибка (MSE) для наивного прогноза:\", mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc9dbJ2V3VpE"
      },
      "source": [
        "✔Создайте функцию lin_pred, которая может по матрице предикторов X и вектору весов линейной модели w получить вектор прогнозов (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvRzCMPA3WMQ"
      },
      "outputs": [],
      "source": [
        "def lin_pred(X, w):\n",
        "    \"\"\"Функция получит предсказания по весам линейной модели\n",
        "\n",
        "    Args:\n",
        "        X (array): матрица предикторов\n",
        "        w (array): вектор весов линейной модели\n",
        "\n",
        "    Returns:\n",
        "        array: вектор прогнозов\n",
        "    \"\"\"\n",
        "    y_pred = X@w\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rskG5jJmDCxU",
        "outputId": "9019149c-94df-4fff-8ddc-f67448c1900e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 2.784126314510936\n"
          ]
        }
      ],
      "source": [
        "# Мы произвели стандартизацию вектора Х, поэтому нам нужно обновить вектор весов w\n",
        "# Обновим веса w для отмасштабированных данных\n",
        "def lin_reg(X, y):\n",
        "    a = np.dot(X.T, X)\n",
        "    b = np.dot(X.T, y)\n",
        "    return np.linalg.solve(a, b)\n",
        "\n",
        "\n",
        "w = lin_reg(X, y).T\n",
        "\n",
        "y_pred = lin_pred(X, w)\n",
        "print(f'MSE: {mse_error(y, y_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Ui2uvd3eYa"
      },
      "source": [
        "✔Создайте функцию stoch_grad_step для реализации шага стохастического градиентного спуска. (1.5 балла) Функция должна принимать на вход следующие аргументы:\n",
        "\n",
        "матрицу X\n",
        "вектора y и w\n",
        "число train_ind - индекс объекта обучающей выборки (строки матрицы X), по которому считается изменение весов\n",
        "число  𝜂  (eta) - шаг градиентного спуска\n",
        "Результатом будет вектор обновленных весов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT8gANOo4Fq0"
      },
      "source": [
        "Шаг для стохастического градиентного спуска выглядит следующим образом:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsMrZwf24MPY"
      },
      "source": [
        "Для того, чтобы написать функцию, нужно сделать следующее:\n",
        "\n",
        "посчитать направление изменения: умножить объект обучающей выборки на 2 и на разницу между предсказанным значением и реальным, а потом поделить на количество элементов в выборке.\n",
        "вернуть разницу между вектором весов и направлением изменения, умноженным на шаг градиентного спуска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMQoIB4c4KUK"
      },
      "outputs": [],
      "source": [
        "def stoch_grad_step(X, y, w, index, eta=0.01):\n",
        "    \"\"\"summary\n",
        "\n",
        "    Args:\n",
        "        X (array): матрица предикторов\n",
        "        y (array): вектор ответов\n",
        "        w (array): вектор весов\n",
        "        train_ind (int): индекс объекта\n",
        "        eta (float): шаг градиентного спуска\n",
        "    Returns:\n",
        "        array: обновленный вектор весов\n",
        "    \"\"\"\n",
        "    x_sample = X[index]\n",
        "    y_sample = y[index]\n",
        "\n",
        "    y_pred = x_sample @ w\n",
        "\n",
        "    gradient = x_sample * (y_pred-y_sample) / len(X)\n",
        "    weights = w - 2 * eta * gradient\n",
        "\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DvTJg3JDJPL",
        "outputId": "4d77754d-7c35-4f8a-f007-d815515d6730"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([14.02261487,  3.91934441,  2.79206845, -0.02267902])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Опять же желательно проверять работоспособность функций\n",
        "stoch_grad_step(X, y, w, 11, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru6LElL84W2-"
      },
      "source": [
        "✔Создайте функцию stochastic_gradient_descent, для реализации стохастического градиентного спуска (2.5 балла)\n",
        "\n",
        "Функция принимает на вход следующие аргументы:\n",
        "\n",
        "Матрицу признаков X\n",
        "Целевую переменнную\n",
        "Изначальную точку (веса модели)\n",
        "Параметр, определяющий темп обучения\n",
        "Максимальное число итераций\n",
        "Евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,при котором алгоритм прекращает работу\n",
        "На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов  𝑤 , а также вектор (список) ошибок."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_xEo5Ic4XfZ"
      },
      "source": [
        "Алгоритм сследующий:\n",
        "\n",
        "*   Инициализируйте расстояние между векторами весов на соседних итерациях большим числом (можно бесконечностью)\n",
        "*   Создайте пустой список для фиксации ошибок\n",
        "*   Создайте счетчик итераций\n",
        "*   Реализуйте оновной цикл обучения пока расстояние между векторами весов больше того, при котором надо прекратить работу (когда расстояния станут слишком маленькими - значит, мы застряли в одном месте) и количество итераций меньше максимально разрешенного: сгенерируйте случайный индекс, запишите текущую ошибку в вектор ошибок, запишите в переменную текущий шаг стохастического спуска с использованием функции, написанной ранее. Далее рассчитайте текущее расстояние между векторами весов и прибавьте к счетчику итераций 1.\n",
        "*   Верните вектор весов и вектор ошибок\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNelROdQDOTI"
      },
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(X, y, w, eta=0.1, max_iter=1e+4, dist_min=1e-8):\n",
        "    \"\"\"Функция реализующая стохастический градиентный спуск\n",
        "\n",
        "    Args:\n",
        "        X (array): матрица предикторов\n",
        "        y (array): вектор ответов\n",
        "        w (array): вектор весов\n",
        "        eta (float): шаг градиентного спуска\n",
        "        max_iter (type): максимальное количество итерации\n",
        "        dist_min (type): минимальное расстояние между векторами весов\n",
        "    \"\"\"\n",
        "\n",
        "    distance = 1e+10 #расстояние между векторами\n",
        "    errors = [] #список для фиксации ошибок\n",
        "    iters = 0\n",
        "\n",
        "    w_value = []\n",
        "\n",
        "    while distance > dist_min and iters < max_iter:\n",
        "        random_ind = np.random.randint(X.shape[0])\n",
        "        y_pred = lin_pred(X, w)\n",
        "\n",
        "        errors.append(mse_error(y, y_pred))\n",
        "        w_new = stoch_grad_step(X, y, w, random_ind, eta)\n",
        "\n",
        "        distance = np.linalg.norm(w - w_new)\n",
        "        w_value.append(w)\n",
        "\n",
        "        w = w_new\n",
        "        iters += 1\n",
        "\n",
        "    return w, w_value, errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hb-V8gC5EMK"
      },
      "source": [
        "✔Запустите  105  итераций стохастического градиентного спуска. Укажите вектор начальных весов, состоящий из нулей. Можете поэкспериментировать с параметром, отвечающим за темп обучения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5WqYB455EUL"
      },
      "source": [
        "✔Постройте график зависимости ошибки от номера итерации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "3ikwH_PhDUzR",
        "outputId": "560ab48a-3a9e-4bd8-ae87-617a47e71717"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7e95af060af0>]"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6aElEQVR4nO3deXhcdaH/8c+ZJZOkyUyaPWmW7qQ7XaANLWWrtlAQpCJwC1RFEGwRqCKiAlevWK5X4QoiqD+limxyZa1YrS10oekKofvekrRp9mYm60ySOb8/0g4EKiRpkjOTvF/Pc54mc07ST3p4Mh/O+X6/xzBN0xQAAEAYsVkdAAAA4OMoKAAAIOxQUAAAQNihoAAAgLBDQQEAAGGHggIAAMIOBQUAAIQdCgoAAAg7DqsDdEUwGFRJSYni4+NlGIbVcQAAQAeYpqna2lplZmbKZvv0ayQRWVBKSkqUnZ1tdQwAANAFxcXFysrK+tRjIrKgxMfHS2r7Ad1ut8VpAABAR/h8PmVnZ4fexz9NRBaUU7d13G43BQUAgAjTkeEZDJIFAABhh4ICAADCDgUFAACEHQoKAAAIOxQUAAAQdigoAAAg7FBQAABA2KGgAACAsENBAQAAYYeCAgAAwg4FBQAAhB0KCgAACDsUlI84VtOou18s1Ft7yq2OAgBAvxaRTzPuKc8UfKBX3jumHce8On9Eshx2+hsAAFbgHfgjbr9wmBJindpfXqeXth61Og4AAP0WBeUjPDFO3XHxCEnSIyv2qd7fYnEiAAD6JwrKx9w4LVc5ibGqqPXrd2sPWR0HAIB+iYLyMVEOm+6dkydJ+s3qQyr3NVmcCACA/oeCchqXjUvXxJwENTa36tF/7bM6DgAA/Q4F5TQMw9APLhslSXpxc7H2ldVanAgAgP6FgvJvTBmcqNlj0hQ0pYf/vsfqOAAA9CsUlE9x75w8OWyGVu0p1/qDlVbHAQCg36CgfIqhKXH6j6k5kqTHVx6wOA0AAP0HBeUzfOOCYXLYDBUcqtL2o16r4wAA0C9QUD7DoIQYXTEhU5L0mzUHLU4DAED/QEHpgFvOHypJenP7cRVVNVicBgCAvo+C0gGjM92aOTJFQVP6/TpWlwUAoKdRUDroGzPbrqK8uKVY1fUBi9MAANC3UVA66LxhSRqT6VZTc1DPFHxgdRwAAPo0CkoHGYahb1wwTJL0p4IjamputTgRAAB9FwWlEy4bm66sgTGqqg/o/7YetToOAAB9FgWlExx2m26eMUSS9Lu1h9QaNC1OBABA30RB6aRrz8lWQqxTH1Q16HdrmdEDAEBPoKB0UmyUQ3deMkJS20MEn9tYZHEiAAD6HgpKF3zlvMG67eSA2R+8ul2vvMd4FAAAuhMFpQsMw9C9c87Sgvxcmab07b+8r79vP251LAAA+gwKShcZhqEHrxijayZnKWhK33rhPb21t9zqWAAA9AkUlDNgsxl6eN54XT4+Q82tpm57ZqsKi2usjgUAQMSjoJwhu83Qo9eerYvzUuVvCeobz2xRua/J6lgAAEQ0Cko3cNpt+uV1Z2tEapzKfH59489b5W9hpVkAALqKgtJN4qOd+t1NU+SOdui9ohr98JUdMk0WcgMAoCsoKN1ocPIA/eo/JslmSC9tPao/rj9idSQAACISBaWbzRyZou9fNkqS9F9/2631ByotTgQAQOShoPSAm2cM0dUTB6k1aOqO59/jyccAAHQSBaUHGIahn149TgNjnaqqD2hvaa3VkQAAiCgUlB4S7bRrdKZbkrT7uM/iNAAARJZOFZQlS5bonHPOUXx8vFJTU3XVVVdp79697Y5pamrSwoULlZSUpLi4OM2bN09lZWXtjikqKtLcuXMVGxur1NRU3XPPPWppaTnznybMjEqnoAAA0BWdKiirV6/WwoULtWHDBq1YsULNzc36/Oc/r/r6+tAxd999t9544w299NJLWr16tUpKSnT11VeH9re2tmru3LkKBAJav369/vjHP2rp0qV64IEHuu+nChOjMk4VFG7xAADQGYZ5Bot1VFRUKDU1VatXr9bMmTPl9XqVkpKi5557Tl/60pckSXv27NGoUaNUUFCgadOm6e9//7suv/xylZSUKC0tTZL01FNP6d5771VFRYWioqI+8+/1+XzyeDzyer1yu91djd/jdpX4dNljaxUf7dC2Bz8vwzCsjgQAgGU68/59RmNQvF6vJCkxMVGStHXrVjU3N2vWrFmhY/Ly8pSTk6OCggJJUkFBgcaNGxcqJ5I0e/Zs+Xw+7dy587R/j9/vl8/na7dFguGpcXLaDdU2tejoiUar4wAAEDG6XFCCwaDuuusuTZ8+XWPHjpUklZaWKioqSgkJCe2OTUtLU2lpaeiYj5aTU/tP7TudJUuWyOPxhLbs7Oyuxu5VUQ6bhqXESWIcCgAAndHlgrJw4ULt2LFDL7zwQnfmOa377rtPXq83tBUXF/f439ldRjMOBQCATutSQVm0aJGWLVumt956S1lZWaHX09PTFQgEVFNT0+74srIypaenh475+KyeU5+fOubjXC6X3G53uy1SnBoou6eUKygAAHRUpwqKaZpatGiRXnnlFa1atUpDhgxpt3/y5MlyOp1auXJl6LW9e/eqqKhI+fn5kqT8/Hxt375d5eXloWNWrFght9ut0aNHn8nPEpY+nMlDQQEAoKMcnTl44cKFeu655/Taa68pPj4+NGbE4/EoJiZGHo9HN998sxYvXqzExES53W7dcccdys/P17Rp0yRJn//85zV69GjdeOON+tnPfqbS0lL98Ic/1MKFC+Vyubr/J7TYqIx4SdIH1Q2q97dogKtT/+QAAPRLnbqC8uSTT8rr9erCCy9URkZGaHvxxRdDxzz66KO6/PLLNW/ePM2cOVPp6el6+eWXQ/vtdruWLVsmu92u/Px83XDDDbrpppv04x//uPt+qjCSFOdSSrxLpintYcl7AAA65IzWQbFKpKyDcspNf9ikNfsq9JOrxuqGablWxwEAwBK9tg4KOubUbR7GoQAA0DEUlF4wmoGyAAB0CgWlF3w41bhWwWDE3VEDAKDXUVB6wdDkAYpy2NQQaFVRdYPVcQAACHsUlF7gsNs0Mo0l7wEA6CgKSi8Zlc44FAAAOoqC0ktOjUPZxTN5AAD4TBSUXsKS9wAAdBwFpZecmmp8rKZR3sZmi9MAABDeKCi9xBPrVKYnWpK0h6soAAB8KgpKL/roeigAAODfo6D0IsahAADQMRSUXkRBAQCgYygovWjcII8kaWeJT2W+JovTAAAQvigovSgnKVZTcgeqJWjq+U1FVscBACBsUVB62Y35uZKk5zcVqbk1aHEaAADCEwWll80Zm67kuCiV+fxasavM6jgAAIQlCkovcznsuu6cHEnSnwqOWBsGAIAwRUGxwH9MzZHNkDYcqtb+MtZEAQDg4ygoFshMiNGsUWmSpGc2fGBxGgAAwg8FxSI35Q+WJL387jHV+VusDQMAQJihoFhk+vAkDU0ZoDp/i15575jVcQAACCsUFIsYhqEbp7VNOX6m4IhM07Q4EQAA4YOCYqGrJ2UpxmnXvrI6bTpcbXUcAADCBgXFQp4Yp66aOEiS9Pt1hy1OAwBA+KCgWOyr0wfLZkj/3FWmtfsrrI4DAEBYoKBYbGRavBacN1iS9MBrO+VvabU2EAAAYYCCEgYWf26kUuNdOlxZr9+uPmR1HAAALEdBCQPx0U798PLRkqRfvXVARVUNFicCAMBaFJQwccX4DE0fniR/S1APvr6DaccAgH6NghImDMPQj68cK6fd0Ft7K/RPnnQMAOjHKChhZFhKnL4xc5gk6Uev71RDgCXwAQD9EwUlzCy8aLiyBsaoxNuk365hwCwAoH+ioISZmCi7vv35kZKkN94vsTgNAADWoKCEoUtGpclpN3Swol6HKuqsjgMAQK+joIQhd7RT04YmSZL+tZvBsgCA/oeCEqZmjUqTJP1rV7nFSQAA6H0UlDB1yahUSdKWD6pVXR+wOA0AAL2LghKmsgbGanSGW0FTWrWHqygAgP6FghLGZo0+dZuHcSgAgP6FghLGPndyHMqa/RVqauYpxwCA/oOCEsbGDnIr3R2thkCrCg5WWR0HAIBeQ0EJY4ZhaNbotsGyK5huDADoRygoYe7UdOOVu8sUDPKEYwBA/0BBCXP5w5I0IMquMp9f2495rY4DAECvoKCEOZfDrpkjUySxqiwAoP+goESAz52cbryC6cYAgH6CghIBLjorVTZD2lNaq+LqBqvjAADQ4ygoEWDggChNGZwoSbrn/97X0ROUFABA30ZBiRB3XDxc0U6bNhyq1uxH1+i5jUUyTWb1AAD6JgpKhDh/RIqW3zlTU3IHqj7Qqu+/sl03/WGTSmoarY4GAEC3o6BEkMHJA/TiN/L1w7mj5HLYtHZ/pWY/ukY7S5h+DADoWygoEcZuM/T184fqzTvP14Qsj2r9LfrW8++pMcCzegAAfQcFJUINS4nT0189V6nxLh2sqNdDb+6yOhIAAN2GghLBEgdE6RdfniBJ+vOGIv2LdVIAAH0EBSXCnT8iRV+fMUSS9N2/blN5bZPFiQAAOHMUlD7gnjlnKS89XtX1AX3npW08VBAAEPEoKH2Ay2HXY9dPlMth05p9FfpjwRGrIwEAcEYoKH3EyLR4/WDuKEnST9/crcdW7legJWhxKgAAuoaC0ofcOC1XV52dqeZWU4+s2KfLH1+rd4tOWB0LAIBOo6D0IYZh6NFrz9YvrztbiQOitK+sTvOeXK8fvbFT9f4Wq+MBANBhFJQ+xjAMXXn2IP1r8QW6etIgmab09DtHNOuR1Xqt8BjP7wEARATDjMB3LJ/PJ4/HI6/XK7fbbXWcsLZ6X4V+8Mp2HT3R9syes7MT9MAVozUpZ6DFyQAA/U1n3r8pKP1AU3Or/t/aQ/r12wfVcHJJ/C9MyNQP5o5Smjva4nQAgP6iM+/f3OLpB6Kddi26eITe/s6FumZylgxDev39Et36zFarowEAcFoUlH4k1R2t/7lmgl5bOF02Q3q/uEbHvY1WxwIA4BMoKP3Q+KwEjctKkCSt219pbRgAAE6j0wVlzZo1uuKKK5SZmSnDMPTqq6+22/+Vr3xFhmG02+bMmdPumOrqas2fP19ut1sJCQm6+eabVVdXd0Y/CDpnxvAkSdI7BygoAIDw0+mCUl9frwkTJuiJJ574t8fMmTNHx48fD23PP/98u/3z58/Xzp07tWLFCi1btkxr1qzRrbfe2vn06LIZw1MkSesOVDH1GAAQdhyd/YJLL71Ul1566ace43K5lJ6eftp9u3fv1vLly7V582ZNmTJFkvT444/rsssu089//nNlZmZ2NhK6YFJugmKcdlXW+bW3rFZ56cyGAgCEjx4Zg/L2228rNTVVZ511lm6//XZVVVWF9hUUFCghISFUTiRp1qxZstls2rhxY0/EwWm4HHadOyRREuNQAADhp9sLypw5c/SnP/1JK1eu1H//939r9erVuvTSS9Xa2rb+RmlpqVJTU9t9jcPhUGJiokpLS0/7Pf1+v3w+X7sNZ+78EcmSpLUUFABAmOn0LZ7Pct1114U+HjdunMaPH69hw4bp7bff1iWXXNKl77lkyRL96Ec/6q6IOGn68LaCsulwtfwtrXI57BYnAgCgTY9PMx46dKiSk5N14MABSVJ6errKy8vbHdPS0qLq6up/O27lvvvuk9frDW3FxcU9HbtfyEuPV3JclBqbW/XuBzVWxwEAIKTHC8rRo0dVVVWljIwMSVJ+fr5qamq0deuHq5iuWrVKwWBQU6dOPe33cLlccrvd7TacOcMwQldRmG4MAAgnnS4odXV1KiwsVGFhoSTp8OHDKiwsVFFRkerq6nTPPfdow4YNOnLkiFauXKkrr7xSw4cP1+zZsyVJo0aN0pw5c3TLLbdo06ZNeuedd7Ro0SJdd911zOCxwIyTBWUtBQUAEEY6XVC2bNmiiRMnauLEiZKkxYsXa+LEiXrggQdkt9u1bds2feELX9DIkSN18803a/LkyVq7dq1cLlfoezz77LPKy8vTJZdcossuu0wzZszQb3/72+77qdBhM04OlN1+tEbehmaL0wAA0IanGUOX/OJtHayo11M3TNKcsRlWxwEA9FE8zRidcv6IU6vKcpsHABAeKCgIDZRlwTYAQLigoEDThibKbjN0pKpBxdUNVscBAICCAik+2qmJ2QmSmG4MAAgPFBRI+vA2z6P/2qcXNxepuTVocSIAQH9GQYEk6bpzs5XpiVaZz697/7pdn3tktV5975hagxE3yQsA0AcwzRghTc2t+vOGD/Tk2wdVVR+QJI1IjdOTN0zS8NR4i9MBACId04zRJdFOu75+/lCt+e5Fumf2WfLEOLW/vE4/emOX1dEAAP0MBQWfMMDl0MKLhuuNRTNkM6S1+yt1oLzW6lgAgH6EgoJ/KycpVrNGpUmSlq4/Ym0YAEC/QkHBp/rq9CGSpL9uPcazegAAvYaCgk81bWii8tLj1djcqhe3FFkdBwDQT1BQ8KkMw9BXpw+WJP1x/QdMOwYA9AoKCj7TlWcP0sBYp47VNGrFrjKr4wAA+gEKCj5TtNOu68/NkSQ9/c5hi9MAAPoDCgo65Mb8XNlthjYertauEp/VcQAAfRwFBR2S4YnRpWPTJUlL13MVBQDQsygo6LBTg2VfLSxRua/J2jAAgD6NgoIOm5QzUOOzPAq0BDXnl2v1/KYiZvUAAHoEBQUdZhiGfval8RqRGqfq+oDue3m7vvjrd/Re0QmrowEA+hgKCjolL92tN+88X/dfPlrxLoe2HfXqi79er+/9dZuaW4NWxwMA9BEUFHSa027TzTOGaNV3LtSXJmdJkl7YXKznN7HSLACge1BQ0GUp8S79/JoJ+s8rRkuSnnjrgJqaWy1OBQDoCygoOGPXT81RpidaZT6/XtxcbHUcAEAfQEHBGXM57PrmRcMlSb9+m6soAIAzR0FBt/jylOzQVRTGogAAzhQFBd0iymHTwovbrqI8+fZBrqIAAM4IBQXd5prJ2RqUEKPyWr+e28hVFABA11FQ0G2iHDYtOnUVZTVXUQAAXUdBQbeaNylLgxJiVFHr17NcRQEAdBEFBd0qymHTHYxFAQCcIQoKut28yVlKd0erss6v1fsqrI4DAIhAFBR0O6fdpsvHZ0iSlm07bnEaAEAkoqCgR1w+IVOStHJ3mRoD3OYBAHQOBQU9YkKWR1kDY9QQaNWqPeVWxwEARBgKCnqEYRiaG7rNU2JxGgBApKGgoMdcMb7tNs+qPeWq87dYnAYAEEkoKOgxYzLdGpwUK39LUCt3l1kdBwAQQSgo6DGGYejyk1dR3nif2TwAgI6joKBHXT6hbRzKmn0V8jU1W5wGABApKCjoUWelxWt4apwCrUGt2MltHgBAx1BQ0KPabvMwmwcA0DkUFPS4U+NQ1u6vVE1DwOI0AIBIQEFBjxueGqe89Hi1BE39Y2ep1XEAABGAgoJeccXJpe95Ng8AoCMoKOgVp8ahvHOgUsXVDRanAQCEOwoKekVu0gDNGJ6soCn9ecMHVscBAIQ5Cgp6zYLzBkuSXthczBOOAQCfioKCXnNxXqqyBsbI29is1wqPWR0HABDGKCjoNXaboZvycyVJS9cfkWmaFicCAIQrCgp61ZenZCvaadOe0lptOlxtdRwAQJiioKBXJcRG6YsTB0mS/lhwxNowAICwRUFBrzs1WPYfO8tUUtNobRgAQFiioKDX5aW7NXVIolqDpp7dyJRjAMAnUVBgia+cvIry/KZiNTUz5RgA0B4FBZb43Og0ZXqiVV0fYPl7AMAnUFBgCYfdpvnT2qYcL3lzt9YfrLQ4EQAgnFBQYJkb83M1OsOtqvqAbvh/G/Wb1QdZGwUAIImCAgu5o5366+3n6epJgxQ0pSV/36Pb//yuapuarY4GALAYBQWWiomy6xfXTNBPrhorp93Q8p2luvJX72h/Wa3V0QAAFqKgwHKGYeiGabn6yzfyleGJ1qHKel31xDtasavM6mgAAItQUBA2JuYM1LI7Zmja0ETVB1p16zNb9KtV+xmXAgD9EAUFYSUpzqVnbp6qm/JzZZrSz/+5T4uee08NgRarowEAehEFBWHHabfpx1eO1ZKrx8lpN/S37cc178kCVdb5rY4GAOglFBSErevPzdFzt0xTclyUdh/36XdrDlkdCQDQSygoCGvnDE7UD+eOliS9w2JuANBvUFAQ9vKHJUmSdpb45G1kjRQA6A86XVDWrFmjK664QpmZmTIMQ6+++mq7/aZp6oEHHlBGRoZiYmI0a9Ys7d+/v90x1dXVmj9/vtxutxISEnTzzTerrq7ujH4Q9F1p7mgNTR4g05Q2Ha62Og4AoBd0uqDU19drwoQJeuKJJ067/2c/+5kee+wxPfXUU9q4caMGDBig2bNnq6mpKXTM/PnztXPnTq1YsULLli3TmjVrdOutt3b9p0CfN3Vo21WUgoNVFicBAPQGwzyDRSYMw9Arr7yiq666SlLb1ZPMzEx9+9vf1ne+8x1JktfrVVpampYuXarrrrtOu3fv1ujRo7V582ZNmTJFkrR8+XJddtllOnr0qDIzMz/z7/X5fPJ4PPJ6vXK73V2Njwjy+vsl+tbz72l0hltv3nm+1XEAAF3Qmffvbh2DcvjwYZWWlmrWrFmh1zwej6ZOnaqCggJJUkFBgRISEkLlRJJmzZolm82mjRs3dmcc9CHThiZKknaX+lTTELA4DQCgp3VrQSktLZUkpaWltXs9LS0ttK+0tFSpqant9jscDiUmJoaO+Ti/3y+fz9duQ/+SGh+t4alxMk1pwyHGoQBAXxcRs3iWLFkij8cT2rKzs62OBAucuoqy4RDjUACgr+vWgpKeni5JKitr/5C3srKy0L709HSVl5e329/S0qLq6urQMR933333yev1hrbi4uLujI0IkT80WRIFBQD6g24tKEOGDFF6erpWrlwZes3n82njxo3Kz8+XJOXn56umpkZbt24NHbNq1SoFg0FNnTr1tN/X5XLJ7Xa329D/TD15BWVPaa2q6xmHAgB9WacLSl1dnQoLC1VYWCipbWBsYWGhioqKZBiG7rrrLv3kJz/R66+/ru3bt+umm25SZmZmaKbPqFGjNGfOHN1yyy3atGmT3nnnHS1atEjXXXddh2bwoP9KjnNpZFqcJGkjV1EAoE9zdPYLtmzZoosuuij0+eLFiyVJCxYs0NKlS/Xd735X9fX1uvXWW1VTU6MZM2Zo+fLlio6ODn3Ns88+q0WLFumSSy6RzWbTvHnz9Nhjj3XDj4O+Ln9okvaV1angUJUuHZdhdRwAQA85o3VQrMI6KP3X8h3Hdduf39XItDj98+4LrI4DAOgEy9ZBAXra1CFtK8ruK6tTZZ3f4jQAgJ5CQUFEGTggSnnp8ZKYzQMAfRkFBRHn1NONKSgA0HdRUBBx8nlwIAD0eRQURJypQ5JkGNLBinqV1DRaHQcA0AMoKIg4nlinxmS2jf6e9chq3ffyNm07WmNtKABAt2KaMSLSuv2VeuD1HTpUUR96bewgt66ZnK0Lz0pRTmKsDMOwMCEA4OM68/5NQUHEMk1Tmw5X67lNRfr79lIFWoOhfVkDY3T+iGRNH56smSNT5I52WpgUACBRUNAPnagP6K/vHtU/d5XpvaITam798D/rDE+0Xl80QynxLgsTAgAoKOjX6v0t2nSkWuv2V+pv246r1NekOWPS9eQNk7jtAwAWYiVZ9GsDXA5ddFaq7r98tH7/lSly2Awt31mqN7YdtzoaAKCDKCjo08ZkenTHxSMkSQ+8tkPltU0WJwIAdAQFBX3eNy8apjGZbtU0NOsHr+xQBN7VBIB+h4KCPs9pt+nn10yQ025oxa4yvVZYYnUkAMBnoKCgXxiV4da3Tt7qefD1nSr3casHAMKZw+oAQG+57cJh+ueuMm0/5tWcX65V1sAYJce5lBwXpZR4l2YMT9G0oYnM9AGAMMA0Y/Qre0trde1vC1TT0Hza/SPT4nRT/mB9ceIgDXDR3wGgO7EOCvApfE3NOlhep8q6gKrq/Kqs8+tIVYPe3H5cDYFWSVK8y6EvTcnSbRcMU5o72uLEANA3UFCALvA2NuuvW4/qmQ0f6HBl2zN+4qMdun/uaF0zJYtbPwBwhigowBkIBk2tPVCpX/xzr7Yd9UqSzh+RrJ9+cZyyE2MtTgcAkYuCAnSDltag/vDOYf3in/vkbwkqNsquxZ8bqcm5A5UQG6WEGKfcMU7ZbVxZAYCOoKAA3ehwZb3u/b9t2nSk+hP7DENKGuDS2EFujR/k0fisBI3P8iiVcSsA8AkUFKCbBYOmnt1UpL9sLlZ1fUA1DQHVnxxQezrjBnn00m35inbaezElAIS3zrx/M48S6ACbzdCN03J147Tc0GuBlqC8jc06eqJB2495te2oV9uO1mh/eZ22H/Nq/cFKXZyXZmFqAIhcFBSgi6IcNqXEu5QS79LEnIGh1+97ebue31SkNfsoKADQVSx1D3SzC0YmS5LW7KuwOAkARC4KCtDN8ocly24zdKiyXsXVDVbHAYCIREEBupknxqmzsxMkSWv2cxUFALqCggL0gJkjUiRxmwcAuoqCAvSAmSfHoaw/UKWW1qDFaQAg8lBQgB4wPitBCbFO1fpbVFhcY3UcAIg4FBSgB9hthqYPZzYPAHQVBQXoIRecHIeyen+lxUkAIPJQUIAecv7JcSjbjtboRH3A4jQAEFkoKEAPyfDEaGRanExTWneAqygA0BkUFKAHMd0YALqGggL0oJkjTxaU/RWKwAeHA4BlKChADzp3SKJcDpvKfH7tK6uzOg4ARAwKCtCDop12TR2aJInbPADQGRQUoIfNHHFyPRSeywMAHUZBAXrYhWe1jUNZu79Sj6/cz1gUAOgACgrQw4anxuvWmUMlSb9YsU+LnntPDYEWi1MBQHijoAC94PuXjdKSq8fJaTf0t+3Hdc1TBTpW02h1LAAIWxQUoJdcf26Onv36NCUOiNLOEp+u/NU6Pb+pSO8X13BFBQA+xjAj8Ia4z+eTx+OR1+uV2+22Og7QKUdPNOjrf9yiPaW17V7PTozRyNR4TcxJ0NShSRqf5ZHLYbcoJQB0v868f1NQAAvU+1v067cPaOsHJ7S/rE5Vp3lWj8th08ScBJ03LFkLzhssT4zTgqQA0H068/7t6KVMAD5igMuhe2bnhT6vqmtbyG1PqU+bj1Rr46FqVdUHtOFQtTYcqla9v0X3XTbKwsQA0Lu4ggKEIdM0dbCiTn/ZclS/XXNII1LjtGLxBVbHAoAz0pn3bwbJAmHIMAwNT43XNy8cJpsh7S+vUwmzfgD0IxQUIIwlxEZpfFaCJGktK9EC6EcoKECYu+DUE5H3VVqcBAB6DwUFCHMzTxaUdQcq1RqMuCFjANAlFBQgzE3I8sgd7ZC3sVnvH62xOg4A9AoKChDmHHabZpx6IvI+xqEA6B8oKEAEmDni1DgUCgqA/oGCAkSAU+NQCotr5G1otjgNAPQ8CgoQATITYjQ8NU5Bs22wLAD0dRQUIEJwmwdAf0JBASLEBWedLCj7KxSBT6gAgE6hoAARYuqQRLkcNh33NulAeZ3VcQCgR1FQgAgR7bTr3CGJkqTV3OYB0MdRUIAIElr2fj8DZQH0bRQUIIKcmm688VCVmppbLU4DAD3HYXUAAB03IjVO6e5olfqa9OXfFCh/WJKmDknU5NxEeWKcVscDgG5DQQEiiGEYuvacbP1y5X5tO+rVtqNe/Wb1IRmGlD80SU/8xyQNHBBldUwAOGOGGYHzFX0+nzwej7xer9xut9VxgF5XVNWgTUeqtelwlTYfOaHDlfWSpCsmZOrx6ydanA4ATq8z799cQQEiUE5SrHKSYvWlyVmSpK0fnNCXf1OgN94v0aVj03XZuAyLEwLAmen2QbL/+Z//KcMw2m15eXmh/U1NTVq4cKGSkpIUFxenefPmqaysrLtjAP3K5NyB+uaFwyRJP3x1hyrr/BYnAoAz0yOzeMaMGaPjx4+HtnXr1oX23X333XrjjTf00ksvafXq1SopKdHVV1/dEzGAfuWOi0coLz1e1fUB3f/qDlabBRDReqSgOBwOpaenh7bk5GRJktfr1e9//3s98sgjuvjiizV58mQ9/fTTWr9+vTZs2NATUYB+I8ph08+vmSCHzdDfd5Rq2bbjVkcCgC7rkYKyf/9+ZWZmaujQoZo/f76KiookSVu3blVzc7NmzZoVOjYvL085OTkqKCjoiShAvzJ2kEeLLh4uSbr/tR0qr22yOBEAdE23F5SpU6dq6dKlWr58uZ588kkdPnxY559/vmpra1VaWqqoqCglJCS0+5q0tDSVlpb+2+/p9/vl8/nabQBOb+FFwzU6w62ahmZ99/+2qd7fYnUkAOi0bi8ol156qa655hqNHz9es2fP1ptvvqmamhr95S9/6fL3XLJkiTweT2jLzs7uxsRA3+K02/TItRPktBt6e2+FPvfIav1z57//HwAACEc9vtR9QkKCRo4cqQMHDig9PV2BQEA1NTXtjikrK1N6evq//R733XefvF5vaCsuLu7h1EBky0t36+mvnKusgTEq8Tbp1me26ut/3KyjJxqsjgYAHdLjBaWurk4HDx5URkaGJk+eLKfTqZUrV4b27927V0VFRcrPz/+338PlcsntdrfbAHy6GSOSteLuC7TwomFy2g39a3e5Zj2yWv+1bJfW7KtQY4Bn+QAIX92+kux3vvMdXXHFFcrNzVVJSYkefPBBFRYWateuXUpJSdHtt9+uN998U0uXLpXb7dYdd9whSVq/fn2H/w5WkgU6Z39ZrX7w6g5tOlwdei3KbtPEnARNH56smSNTNH6QRzabYWFKAH2dpSvJHj16VNdff72qqqqUkpKiGTNmaMOGDUpJaXsK66OPPiqbzaZ58+bJ7/dr9uzZ+vWvf93dMQB8xIi0eL146zT9Y2eZ/rW7TOsPVKrE26SNh6u18XC1HlmxT8lxLl10VoouzkvVjBHJio/m4YMArMOzeIB+yDRNHalq0DsHKrVuf6XWHahU3Udm+zjthmaOSNGVEwfpc6PSFBNltzAtgL6iM+/fFBQACrQEtflItVbtKdfK3WU6UvXhYNoBUXbNHpOuL04apBnDk2UY3AYC0DUUFABnZF9ZrV4vLNGrhcd09ERj6PWvTR+i+y8fRUkB0CUUFADdwjRNvVt0Qn9995ie29i2IvS9c/J0+8kHEwJAZ1g6SBZA32EYhibnJmpybqKGJg/QT/62W/+9fI+S4qL05SksmAig5/T4OigA+oavnz9U37hgqCTpvpe3a+XuMosTAejLKCgAOux7c/I0b1KWWoOmFj73rrZ+UP3ZXwQAXUBBAdBhhmHo4XnjdNFZKWpqDuprS7foQHmt1bEA9EEUFACd4rTb9MT8SZqYkyBvY7MW/GGzyn1NVscC0MdQUAB0WmyUQ79fcI6GJA/QsZpGfe2Pm1X/kYXeAOBMUVAAdEnigCgt/eo5ShoQpR3HfFr43LtqaQ1aHQtAH0FBAdBluUkD9P8WTFG006a391boh6/uUAQurQQgDFFQAJyRiTkD9dh1E2UzpBc2F+uhv+3WhkNVOlRRp9qmZgoLgC5hJVkA3eJPBUf0wGs7P/F6tNOmcYM8WnDeYM0Zky6Hnf8vAvorVpIF0Otuyh8sm2Ho9cISVdb5VVHrV62/RU3NQW0+ckKbj5zQoIQYLTgvV9eekyNPjNPqyADCGFdQAPSYxkCrjnsb9Vphif684QNV1QckSbEnn5B83rAknTc8WYMSYixOCqA38LBAAGGnqblVrxeW6PfrDmtvWfvF3XKTYnXesCTNHZep84YlyWbjaclAX0RBARC2TNPU5iMntHpfudYfrNK2o161Bj/8NTQ0eYDmT8vVlyZlyRPLbSCgL6GgAIgYtU3N2nykWqv2lOvV90pUd3LBt2inTVdOGKQb83M1dpDH4pQAugMFBUBEqve36NXCY3qm4APtKf3wNtCknATdlD9Yl45Ll8thtzAhgDNBQQEQ0UzT1NYPTuhPBR/o7zuOq7m17ddUclyUrj0nW9dMztbg5AEWpwTQWRQUAH1GeW2TXthUrOc2Fqn0Iw8lnJw7UFdPGqTLx2UyVgWIEBQUAH1Oc2tQK3aV6YXNxVq3v0KnxtVG2W2aOTJFZ2d7NGaQR2My3UqNj7Y2LIDToqAA6NPKfU16rbBEf333aLuxKqekxLs0bpBHE7MTNDFnoCZkexQfzVUWwGoUFAD9xq4Sn9bur9DOEp92lnh1qLJeH/+tZhjSiNQ4jcpwK3tgrHISY5WVGKOcxFgNSoiRYbDuCtAbWOoeQL8xOtOt0Zkf/qJrCLRo93Gf3i/2qrC4Ru8Vn1BxdaP2ldVpX1ndJ77+snHpevz6SbKzOBwQVigoAPqU2CiHJucmanJuYui1ilq/CotrdLiyTkXVDSqqblRxdYOKqhv05vZS5Sbt1b1z8ixMDeDjKCgA+ryUeJc+NzpNUlq7118rPKY7XyjUk28f1NhMj+aOz7AmIIBP4LnnAPqtK88epFvOHyJJ+s5L72tPqc/iRABOoaAA6NfunZOn6cOT1Njcqlv/tFU1DQGrIwEQBQVAP+ew2/Sr6ycpa2CMiqobdMfz77V7eCEAazDNGADUNl356iffUVNzUNmJMZqUM1BnZyfo7OwEjc508wwgoBuwDgoAdMGb24/rrhcLFWgJtns9ymHTpWPTNX9qrs4ZPJB1U4AuoqAAQBd5G5pVeLRG7xfXqPDkVl3/4biU4alxmj81R1dPypInhtVpgc6goABANzFNU9uPefXcxiK9VliixuZWSVKM067bLxymW2cOVbST2z9AR1BQAKAH+Jqa9ep7x/TshiLtLWt7BlDWwBj9cO4ozR6Tzq0f4DNQUACgB5mmqTe2HddP/7Zbpb4mSdJ5w5J075w8jc50y2lngiRwOhQUAOgFDYEWPfn2Qf1mzaHQwFqHzVBuUqyGpcRpaEqchqYM0OCkARqcFKuUeBdXWdCvUVAAoBcVVzfo4eV7tGp3eWiMyunERtmVmzRAKfEuxbscinM5FBftUHy0Q2MzPTpveJJio3gCCfouCgoAWCAYNFXqa9LBijodLK/TwYp6Halq246daNRnrf8W5bApf2iSLs5L1UVnpSonKbZ3ggO9hIICAGEm0BLU0RMN+qCqQdX1AdX5W1Tnb1FtU4uq6vxaf7BKx2oa233NsJQBbWUlL1VTchMV5WBsCyIbBQUAIoxpmjpQXqdVe8q1ak+5tnxwot2S+3Euh6YPT9L4rATlpccrL8OtTE80Y1oQUSgoABDhvI3NWru/Qm/tqdDqfeWqrPvkQwzjox0amhInT4wzNKYlPtohT4xTyfEuJce5lBLvUnJclJIGuBTttFFoYCkKCgD0IcFg22JxBYeqtOe4T3tKa3WgvE4tnXyoYZTDpoQYpwbGRskT61RuYqxGZ7o1KqNtY2Vc9DQKCgD0cYGWoA5W1KmoukF1TS2qbWpuG9Pib1FNfbMq6/wnt4Aqav0KtAY/83sOSojR8NQ4DUlumxY9OHmAhqXEKTuRwbroHhQUAECIaZpqCLTqRENANQ3N8jY2q6o+oAPlddpV4tPu475PDND9qPNHJOu7s/M0LsvTi6nRF1FQAACd4m1o1u5Snw5X1utIZX3bn1X1OlRRH7qVNHd8hr79uZEamhJncVpEKgoKAKBbFFc36JEV+/Rq4TGZpmS3Gbp64iBNzBmonMRYZSfGKDMhhuX90SEUFABAt9p93Kf/+cderdpT/ol9NkPK8MRo0MAYZSW0/Tkooa24pHuileaOljvawQwiUFAAAD1j0+Fqvbn9uIqqG1RU3aDi6gb5Wz57AG6M064MT7RGpMXp3CFJmjokUaMy3LLbKC39CQUFANArgkFTlXV+FZ9o0NETjTpW06hjJ/88XtOkUl+TvI3Np/3aeJdDkwcPlCfGKX9zUP6WVvlbgmoNmpqUO1BzxqRrfJaHKy99CAUFABA2GgOtKvM1qcTbqG1Hvdp4qEpbjpxQrb/lM792UEKMZo9J1+wxaRqflaCYKHsvJEZPoaAAAMJaa9DU7uM+vVt0QoGWoKKddrkcNrmcdgVagnprT7ne2luuhsCHT4e2GdLQlDiNynBrdIZbozLiNTrTrdT4aAt/EnQGBQUAEPGamlu1el+F/rGjVGv2V5x2uX9JSo6LUl56W2EZkRavTE+M0j0upXtiFOdy9HJqfBoKCgCgTzFNUxW1fu067mvbTi4wd7iyXp+24n+8y6GBA6IUG2VXTJRdMU77yY8dinHaFBvlULTTrjiXXWdnD9TUoYlMme5BnXn/ploCAMKeYRhKdUcr1R2tC89KDb3eGGjVvrJa7TreVliOVDWo1Nuo494m1Ta1Lf3fkbEup3hinJo1Kk2zx6Rp5sgURTsZ82IVrqAAAPqkOn+LSr1ts4gaA61qCLSosblVDYFWNQZaT37cosZAUNX1fq3dX6mq+g9vI7kcNg1KiFFynEvJ8VFKjnNpYGyUXE6bouw2uRw2Oe02Oew2GZJOTTYyDMk0pZagqWDQbPvTNOVy2OSJccod45Tn5JYc5+pXJYgrKACAfi/O5dDw1I4vy98aNLXlSLWW7yzVP3eW6VhNow5V1utQZX0PppTiox1KiXcpJc6l5HiXHDZDQVMKmqZM05QhQ+4YhxJiozQw1qmE2Ch5YpwfDix22ORy2BV18uMoR1uBijr5scNmRORUba6gAADwMaZp6khVg8p8TW1Pha71q6o+oOr6gAItQQVag2puDSrQElRzqynz5Nd8lMNmyP6Rzd8cVE1j28MavY3N8jY0d+gp02fKMCSn3SbXydIywOVQQmzbFZy2suOQ3TBCV3pag6Zag1L+sCR9aXJWt2bhCgoAAGfAMAwNSR6gIckDeuzvME1Ttf4WVdT6Ve7zq6LOr6o6v4Jm25Rqm2HIZkhBU/I2NutEQ0An6gM60dAsX1OzAi1B+VtOLnDXHFRTc6sCJ0vTRwcOm6baSlVLUPJLVfUBFVV/dj6X09btBaUzKCgAAFjAMAy5o51yRzs1rJufEN3SevIqT4spf2tr6EpPoCWoOn+zahpObiev5sg0ZbMZshuGbDZDDpuh0ZnW3qGgoAAA0Mc4Tg7eVZQkOa2O0yVM9gYAAGGHggIAAMIOBQUAAIQdCgoAAAg7FBQAABB2KCgAACDsWFpQnnjiCQ0ePFjR0dGaOnWqNm3aZGUcAAAQJiwrKC+++KIWL16sBx98UO+++64mTJig2bNnq7y83KpIAAAgTFhWUB555BHdcsst+upXv6rRo0frqaeeUmxsrP7whz9YFQkAAIQJSwpKIBDQ1q1bNWvWrA+D2GyaNWuWCgoKrIgEAADCiCVL3VdWVqq1tVVpaWntXk9LS9OePXs+cbzf75ff7w997vP5ejwjAACwTkTM4lmyZIk8Hk9oy87OtjoSAADoQZYUlOTkZNntdpWVlbV7vaysTOnp6Z84/r777pPX6w1txcXFvRUVAABYwJJbPFFRUZo8ebJWrlypq666SpIUDAa1cuVKLVq06BPHu1wuuVyu0OemaUriVg8AAJHk1Pv2qffxT2NJQZGkxYsXa8GCBZoyZYrOPfdc/e///q/q6+v11a9+9TO/tra2VpK41QMAQASqra2Vx+P51GMsKyjXXnutKioq9MADD6i0tFRnn322li9f/omBs6eTmZmp4uJixcfHyzCMbs3l8/mUnZ2t4uJiud3ubv3e6BjOgfU4B9bjHFiPc9D9TNNUbW2tMjMzP/NYw+zIdZZ+xOfzyePxyOv18h+kRTgH1uMcWI9zYD3OgbUiYhYPAADoXygoAAAg7FBQPsblcunBBx9sN2sIvYtzYD3OgfU4B9bjHFiLMSgAACDscAUFAACEHQoKAAAIOxQUAAAQdigoAAAg7FBQPuKJJ57Q4MGDFR0dralTp2rTpk1WR+qzlixZonPOOUfx8fFKTU3VVVddpb1797Y7pqmpSQsXLlRSUpLi4uI0b968TzxgEt3n4YcflmEYuuuuu0KvcQ563rFjx3TDDTcoKSlJMTExGjdunLZs2RLab5qmHnjgAWVkZCgmJkazZs3S/v37LUzct7S2tur+++/XkCFDFBMTo2HDhum//uu/2j0rhnNgEROmaZrmCy+8YEZFRZl/+MMfzJ07d5q33HKLmZCQYJaVlVkdrU+aPXu2+fTTT5s7duwwCwsLzcsuu8zMyckx6+rqQsfcdtttZnZ2trly5Upzy5Yt5rRp08zzzjvPwtR916ZNm8zBgweb48ePN++8887Q65yDnlVdXW3m5uaaX/nKV8yNGzeahw4dMv/xj3+YBw4cCB3z8MMPmx6Px3z11VfN999/3/zCF75gDhkyxGxsbLQwed/x0EMPmUlJSeayZcvMw4cPmy+99JIZFxdn/vKXvwwdwzmwBgXlpHPPPddcuHBh6PPW1lYzMzPTXLJkiYWp+o/y8nJTkrl69WrTNE2zpqbGdDqd5ksvvRQ6Zvfu3aYks6CgwKqYfVJtba05YsQIc8WKFeYFF1wQKiicg5537733mjNmzPi3+4PBoJmenm7+z//8T+i1mpoa0+Vymc8//3xvROzz5s6da37ta19r99rVV19tzp8/3zRNzoGVuMUjKRAIaOvWrZo1a1boNZvNplmzZqmgoMDCZP2H1+uVJCUmJkqStm7dqubm5nbnJC8vTzk5OZyTbrZw4ULNnTu33b+1xDnoDa+//rqmTJmia665RqmpqZo4caJ+97vfhfYfPnxYpaWl7c6Bx+PR1KlTOQfd5LzzztPKlSu1b98+SdL777+vdevW6dJLL5XEObCSZU8zDieVlZVqbW39xJOU09LStGfPHotS9R/BYFB33XWXpk+frrFjx0qSSktLFRUVpYSEhHbHpqWlqbS01IKUfdMLL7ygd999V5s3b/7EPs5Bzzt06JCefPJJLV68WN///ve1efNmfetb31JUVJQWLFgQ+nc+3e8mzkH3+N73viefz6e8vDzZ7Xa1trbqoYce0vz58yWJc2AhCgost3DhQu3YsUPr1q2zOkq/UlxcrDvvvFMrVqxQdHS01XH6pWAwqClTpuinP/2pJGnixInasWOHnnrqKS1YsMDidP3DX/7yFz377LN67rnnNGbMGBUWFuquu+5SZmYm58Bi3OKRlJycLLvd/onZCWVlZUpPT7coVf+waNEiLVu2TG+99ZaysrJCr6enpysQCKimpqbd8ZyT7rN161aVl5dr0qRJcjgccjgcWr16tR577DE5HA6lpaVxDnpYRkaGRo8e3e61UaNGqaioSJJC/878buo599xzj773ve/puuuu07hx43TjjTfq7rvv1pIlSyRxDqxEQZEUFRWlyZMna+XKlaHXgsGgVq5cqfz8fAuT9V2maWrRokV65ZVXtGrVKg0ZMqTd/smTJ8vpdLY7J3v37lVRURHnpJtccskl2r59uwoLC0PblClTNH/+/NDHnIOeNX369E9Mr9+3b59yc3MlSUOGDFF6enq7c+Dz+bRx40bOQTdpaGiQzdb+rdButysYDEriHFjK6lG64eKFF14wXS6XuXTpUnPXrl3mrbfeaiYkJJilpaVWR+uTbr/9dtPj8Zhvv/22efz48dDW0NAQOua2224zc3JyzFWrVplbtmwx8/Pzzfz8fAtT930fncVjmpyDnrZp0ybT4XCYDz30kLl//37z2WefNWNjY80///nPoWMefvhhMyEhwXzttdfMbdu2mVdeeSVTXLvRggULzEGDBoWmGb/88stmcnKy+d3vfjd0DOfAGhSUj3j88cfNnJwcMyoqyjz33HPNDRs2WB2pz5J02u3pp58OHdPY2Gh+85vfNAcOHGjGxsaaX/ziF83jx49bF7of+HhB4Rz0vDfeeMMcO3as6XK5zLy8PPO3v/1tu/3BYNC8//77zbS0NNPlcpmXXHKJuXfvXovS9j0+n8+88847zZycHDM6OtocOnSo+YMf/MD0+/2hYzgH1jBM8yPL5QEAAIQBxqAAAICwQ0EBAABhh4ICAADCDgUFAACEHQoKAAAIOxQUAAAQdigoAAAg7FBQAABA2KGgAACAsENBAQAAYYeCAgAAwg4FBQAAhJ3/Dxf7sfE1L752AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "w, w_values, errors = stochastic_gradient_descent(X, y, np.zeros(X.shape[1]), 2, 1e+5, dist_min=1e-3)\n",
        "plt.plot(errors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipPJKDsR6sgO"
      },
      "source": [
        "\n",
        "Выведите вектор весов, к которому сошелся метод."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FCrh2H96tSv",
        "outputId": "e7b1d37e-a3cb-4ec9-fde3-a5ca37fc0a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Вектор весов, к которому сошелся метод: [11.8175842   3.23549403  2.16586204  0.27896789]\n"
          ]
        }
      ],
      "source": [
        "print(f'Вектор весов, к которому сошелся метод: {w}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT3hWB916yia"
      },
      "source": [
        "Выведите среднеквадратичную ошибку на последней итерации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUeCfJuG6zLC",
        "outputId": "dfa8bd91-082d-47a2-c045-acb94fbb0a0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.486206697768452"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mse_error(X@w, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sqeVoiVDqsG",
        "outputId": "4dd9d680-7ba5-4c14-d4a2-8cb9905037c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Минимальная целевая метрика достигнута на       92 итерации, и составила       8.446130083664393       \n",
            "Веса линейной регрессии при этом составили [11.82728595  3.24411377  2.15348683  0.28740259]\n"
          ]
        }
      ],
      "source": [
        "# Для поиска итерации на которой достигнут минимум целевой метрики используем Pandas\n",
        "model_data = pd.DataFrame({'MSE': errors, 'w_value': w_values})\n",
        "w_optimal = model_data.iloc[model_data['MSE'].idxmin()][1]\n",
        "\n",
        "print(f'Минимальная целевая метрика достигнута на \\\n",
        "      {model_data[\"MSE\"].idxmin()} итерации, и составила \\\n",
        "      {errors[model_data[\"MSE\"].idxmin()]} \\\n",
        "      \\nВеса линейной регрессии при этом составили {w_optimal}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2Wr8gFl61Zh"
      },
      "source": [
        "БОНУСНОЕ ЗАДАНИЕ\n",
        "Разумеется, в реальности специалисты по машинному обучению не прописывают алгоритмы с нуля, а пользуются готовыми реализациями из библиотек. Реализованный Вами стохастический градиентный спуск представлен в библиотеке sklearn.\n",
        "\n",
        "Что необходимо сделать:\n",
        "\n",
        "Выберите в документации класс, подходящий для вашей задачи, и обучите стохастический градиентный спуск. Оцените качество с помощью среднеквадратичной ошибки и сравните результат с результатом алгоритма, реализованного вами самостоятельно. В одном из предыдущих модулей качество решения задачи регрессии оценивалось с помощью ещё одной метрики. Найдите её реализацию в библиотеке sklearn и оцените качество полученной модели. Данное задание не является обязательным, но, выполнив его, вы получите возможность заработать дополнительные 3 балла."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRyXWM3G65hS",
        "outputId": "3f18d6f1-e75c-4213-cbc6-63dab705fe33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2023-12-24 13:03:18,564] A new study created in memory with name: no-name-f1550acb-0210-422c-ba72-804ea07b18c6\n",
            "[I 2023-12-24 13:03:18,577] Trial 0 finished with value: 3.1723071991423746 and parameters: {'max_iter': 3274, 'tol': 0.000134229753032232, 'l1_ratio': 0.8897047055919644}. Best is trial 0 with value: 3.1723071991423746.\n",
            "[I 2023-12-24 13:03:18,591] Trial 1 finished with value: 3.1975628404933523 and parameters: {'max_iter': 6275, 'tol': 0.0038904498399382078, 'l1_ratio': 0.7966146092003898}. Best is trial 0 with value: 3.1723071991423746.\n",
            "[I 2023-12-24 13:03:18,604] Trial 2 finished with value: 3.172389492844331 and parameters: {'max_iter': 7776, 'tol': 2.9066871485126298e-05, 'l1_ratio': 0.6249284422975172}. Best is trial 0 with value: 3.1723071991423746.\n",
            "[I 2023-12-24 13:03:18,617] Trial 3 finished with value: 3.172493333741611 and parameters: {'max_iter': 5186, 'tol': 3.161551914870035e-05, 'l1_ratio': 0.2909011836070793}. Best is trial 0 with value: 3.1723071991423746.\n",
            "[I 2023-12-24 13:03:18,630] Trial 4 finished with value: 3.19054431007691 and parameters: {'max_iter': 4405, 'tol': 0.0029571276221677582, 'l1_ratio': 0.23075484154491105}. Best is trial 0 with value: 3.1723071991423746.\n",
            "[I 2023-12-24 13:03:18,642] Trial 5 finished with value: 3.171151413997003 and parameters: {'max_iter': 9722, 'tol': 0.000338457505873171, 'l1_ratio': 0.23030506788680888}. Best is trial 5 with value: 3.171151413997003.\n",
            "[I 2023-12-24 13:03:18,654] Trial 6 finished with value: 3.180437347138162 and parameters: {'max_iter': 9323, 'tol': 0.00040535672820443154, 'l1_ratio': 0.2529359341585907}. Best is trial 5 with value: 3.171151413997003.\n",
            "[I 2023-12-24 13:03:18,666] Trial 7 finished with value: 3.1975844121921084 and parameters: {'max_iter': 5111, 'tol': 0.004622562270796046, 'l1_ratio': 0.7290848992308223}. Best is trial 5 with value: 3.171151413997003.\n",
            "[I 2023-12-24 13:03:18,678] Trial 8 finished with value: 3.1976378225088617 and parameters: {'max_iter': 3526, 'tol': 0.0041937180542228406, 'l1_ratio': 0.5618983274768357}. Best is trial 5 with value: 3.171151413997003.\n",
            "[I 2023-12-24 13:03:18,694] Trial 9 finished with value: 3.1725499796327385 and parameters: {'max_iter': 3979, 'tol': 4.62552355074982e-05, 'l1_ratio': 0.10872289931858542}. Best is trial 5 with value: 3.171151413997003.\n",
            "[I 2023-12-24 13:03:18,729] Trial 10 finished with value: 3.180383335118864 and parameters: {'max_iter': 9397, 'tol': 0.0004626197934177296, 'l1_ratio': 0.42490987132161434}. Best is trial 5 with value: 3.171151413997003.\n",
            "[I 2023-12-24 13:03:18,785] Trial 11 finished with value: 3.2263906313237327 and parameters: {'max_iter': 619, 'tol': 0.09375581391519601, 'l1_ratio': 0.8810388271060654}. Best is trial 5 with value: 3.171151413997003.\n",
            "[I 2023-12-24 13:03:18,855] Trial 12 finished with value: 3.1724507281403036 and parameters: {'max_iter': 2034, 'tol': 0.00013210340404257344, 'l1_ratio': 0.4279412709339959}. Best is trial 5 with value: 3.171151413997003.\n",
            "[I 2023-12-24 13:03:18,945] Trial 13 finished with value: 3.1710942245061373 and parameters: {'max_iter': 7193, 'tol': 0.00019519910861230097, 'l1_ratio': 0.4150053846645213}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:18,982] Trial 14 finished with value: 3.17247034062249 and parameters: {'max_iter': 7626, 'tol': 1.057410567311737e-05, 'l1_ratio': 0.36485632887575914}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,023] Trial 15 finished with value: 3.182188910208666 and parameters: {'max_iter': 10000, 'tol': 0.0007656009191638412, 'l1_ratio': 0.12078858956862906}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,063] Trial 16 finished with value: 3.1988419946376085 and parameters: {'max_iter': 7985, 'tol': 0.015081084974825975, 'l1_ratio': 0.5095165061473195}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,112] Trial 17 finished with value: 3.171115363338237 and parameters: {'max_iter': 6543, 'tol': 0.00018122943011760747, 'l1_ratio': 0.34673196184410215}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,160] Trial 18 finished with value: 3.172473780829078 and parameters: {'max_iter': 6579, 'tol': 0.0001326009497259186, 'l1_ratio': 0.3537909721557023}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,202] Trial 19 finished with value: 3.188846228446831 and parameters: {'max_iter': 6154, 'tol': 0.0015586381534518805, 'l1_ratio': 0.585003304396525}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,246] Trial 20 finished with value: 3.172444003820141 and parameters: {'max_iter': 6960, 'tol': 7.989705543872258e-05, 'l1_ratio': 0.4495712215526485}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,288] Trial 21 finished with value: 3.171167508531807 and parameters: {'max_iter': 8470, 'tol': 0.00026789502683920776, 'l1_ratio': 0.17833052760962465}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,329] Trial 22 finished with value: 3.1711300241355476 and parameters: {'max_iter': 8603, 'tol': 0.00027628213297862327, 'l1_ratio': 0.2993831448573171}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,371] Trial 23 finished with value: 3.182120140386338 and parameters: {'max_iter': 8364, 'tol': 0.0008366634173369343, 'l1_ratio': 0.3392646302930282}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,419] Trial 24 finished with value: 3.17243256887994 and parameters: {'max_iter': 5824, 'tol': 1.3582059420395751e-05, 'l1_ratio': 0.4863545220113221}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,463] Trial 25 finished with value: 3.1711033644317688 and parameters: {'max_iter': 7168, 'tol': 0.00020518831073223885, 'l1_ratio': 0.38548515269374906}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,504] Trial 26 finished with value: 3.172462824958198 and parameters: {'max_iter': 7272, 'tol': 6.11115067576621e-05, 'l1_ratio': 0.38903063906120977}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,546] Trial 27 finished with value: 3.188873950626 and parameters: {'max_iter': 6956, 'tol': 0.001514618066596207, 'l1_ratio': 0.497902401512211}. Best is trial 13 with value: 3.1710942245061373.\n",
            "[I 2023-12-24 13:03:19,588] Trial 28 finished with value: 3.1710216944054643 and parameters: {'max_iter': 5564, 'tol': 0.00016400551670639368, 'l1_ratio': 0.6492874647843678}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:19,634] Trial 29 finished with value: 3.172376422691208 and parameters: {'max_iter': 2420, 'tol': 2.6014559027561515e-05, 'l1_ratio': 0.6669775036229284}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:19,684] Trial 30 finished with value: 3.172363801248962 and parameters: {'max_iter': 5535, 'tol': 9.932047124199611e-05, 'l1_ratio': 0.7075842578509799}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:19,728] Trial 31 finished with value: 3.1710542727991724 and parameters: {'max_iter': 4358, 'tol': 0.00028153374084615487, 'l1_ratio': 0.5440496475524533}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:19,772] Trial 32 finished with value: 3.171056440518938 and parameters: {'max_iter': 4379, 'tol': 0.00019529041003992412, 'l1_ratio': 0.5370475733480908}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:19,812] Trial 33 finished with value: 3.1820532110326205 and parameters: {'max_iter': 4340, 'tol': 0.0006621735255668284, 'l1_ratio': 0.5519264682330779}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:19,853] Trial 34 finished with value: 3.1723920685870226 and parameters: {'max_iter': 2702, 'tol': 4.7354215271145644e-05, 'l1_ratio': 0.6166419680283225}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:19,932] Trial 35 finished with value: 3.1887866777640164 and parameters: {'max_iter': 4900, 'tol': 0.0016667604990627867, 'l1_ratio': 0.7721246721367018}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:19,981] Trial 36 finished with value: 3.1723845705413907 and parameters: {'max_iter': 3360, 'tol': 0.00010214982409439445, 'l1_ratio': 0.6407642287101446}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:20,023] Trial 37 finished with value: 3.1803504596037757 and parameters: {'max_iter': 4808, 'tol': 0.0004893782738077976, 'l1_ratio': 0.5295959224770499}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:20,075] Trial 38 finished with value: 3.172396315713557 and parameters: {'max_iter': 5611, 'tol': 2.4064419479306287e-05, 'l1_ratio': 0.6029785648998842}. Best is trial 28 with value: 3.1710216944054643.\n",
            "[I 2023-12-24 13:03:20,120] Trial 39 finished with value: 3.1710095770708255 and parameters: {'max_iter': 3843, 'tol': 0.00020346202169992862, 'l1_ratio': 0.6884321840694948}. Best is trial 39 with value: 3.1710095770708255.\n",
            "[I 2023-12-24 13:03:20,165] Trial 40 finished with value: 3.1987840079013004 and parameters: {'max_iter': 3892, 'tol': 0.011310868570822086, 'l1_ratio': 0.6916150928577522}. Best is trial 39 with value: 3.1710095770708255.\n",
            "[I 2023-12-24 13:03:20,200] Trial 41 finished with value: 3.1709629168793563 and parameters: {'max_iter': 4376, 'tol': 0.0001774776578354567, 'l1_ratio': 0.8391775801252455}. Best is trial 41 with value: 3.1709629168793563.\n",
            "[I 2023-12-24 13:03:20,230] Trial 42 finished with value: 3.1709710586356836 and parameters: {'max_iter': 4516, 'tol': 0.000375175812049148, 'l1_ratio': 0.8128727040875415}. Best is trial 41 with value: 3.1709629168793563.\n",
            "[I 2023-12-24 13:03:20,256] Trial 43 finished with value: 3.1709586603985103 and parameters: {'max_iter': 3081, 'tol': 0.0003762320537916458, 'l1_ratio': 0.8529298846227388}. Best is trial 43 with value: 3.1709586603985103.\n",
            "[I 2023-12-24 13:03:20,282] Trial 44 finished with value: 3.1819590713202506 and parameters: {'max_iter': 2888, 'tol': 0.0010651819937358515, 'l1_ratio': 0.8511015298052534}. Best is trial 43 with value: 3.1709586603985103.\n",
            "[I 2023-12-24 13:03:20,308] Trial 45 finished with value: 3.1802620143142097 and parameters: {'max_iter': 1647, 'tol': 0.00046058791703748505, 'l1_ratio': 0.8112736249482602}. Best is trial 43 with value: 3.1709586603985103.\n",
            "[I 2023-12-24 13:03:20,334] Trial 46 finished with value: 3.190374778853391 and parameters: {'max_iter': 3766, 'tol': 0.002670055170820409, 'l1_ratio': 0.7651150617878031}. Best is trial 43 with value: 3.1709586603985103.\n",
            "[I 2023-12-24 13:03:20,361] Trial 47 finished with value: 3.1723065114997366 and parameters: {'max_iter': 1257, 'tol': 7.431963427225464e-05, 'l1_ratio': 0.8919173895485553}. Best is trial 43 with value: 3.1709586603985103.\n",
            "[I 2023-12-24 13:03:20,388] Trial 48 finished with value: 3.170966633475198 and parameters: {'max_iter': 3028, 'tol': 0.0003822326232625779, 'l1_ratio': 0.8271697132213169}. Best is trial 43 with value: 3.1709586603985103.\n",
            "[I 2023-12-24 13:03:20,415] Trial 49 finished with value: 3.180254150694801 and parameters: {'max_iter': 3100, 'tol': 0.0006059151968072213, 'l1_ratio': 0.836320242826852}. Best is trial 43 with value: 3.1709586603985103.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE on test data: 3.1709586603985103\n",
            "MAE on test data: 1.4621717291267413\n",
            "Best hyperparameters: {'max_iter': 3081, 'tol': 0.0003762320537916458, 'l1_ratio': 0.8529298846227388}\n"
          ]
        }
      ],
      "source": [
        "X = df.drop(['sales', 'Unnamed: 0'], axis=1)\n",
        "y = df['sales']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "def objective(trial):\n",
        "    # Define the hyperparameters to tune via Optuna\n",
        "    max_iter = trial.suggest_int('max_iter', 100, 10000)\n",
        "    tol = trial.suggest_float('tol', 1e-5, 1e-1, log=True)  # Updated method here\n",
        "    l1_ratio = trial.suggest_float('l1_ratio', 0.1, 0.9)  # Assuming this was updated earlier\n",
        "\n",
        "    # Create an instance of the SGDRegressor with the current hyperparameters\n",
        "    sgd_reg = SGDRegressor(\n",
        "        penalty='elasticnet',\n",
        "        max_iter=max_iter,\n",
        "        tol=tol,\n",
        "        l1_ratio=l1_ratio,\n",
        "        random_state=42,\n",
        "    )\n",
        "\n",
        "    # Fit the SGDRegressor to the scaled training data\n",
        "    sgd_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions on the scaled testing data\n",
        "    y_pred = sgd_reg.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate MSE on test data\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    return mse\n",
        "\n",
        "# Create a study object and specify the direction is 'minimize'.\n",
        "study = optuna.create_study(direction='minimize')\n",
        "\n",
        "# Optimize the study, the objective function is passed in as the first argument.\n",
        "study.optimize(objective, n_trials=50)  # You can specify the number of trials\n",
        "\n",
        "# Extract the best estimator\n",
        "best_params = study.best_params\n",
        "best_sgd_reg = SGDRegressor(\n",
        "    penalty='elasticnet',\n",
        "    max_iter=best_params['max_iter'],\n",
        "    tol=best_params['tol'],\n",
        "    l1_ratio=best_params['l1_ratio'],\n",
        "    random_state=42,\n",
        ")\n",
        "best_sgd_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions with the best parameters\n",
        "y_pred = best_sgd_reg.predict(X_test_scaled)\n",
        "\n",
        "# Calculate MSE and MAE on test data\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE on test data: {mse}\")\n",
        "print(f\"MAE on test data: {mae}\")\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(\"Best hyperparameters:\", best_params)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}